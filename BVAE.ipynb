{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103c088d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from pyro.contrib.examples.util import MNIST\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "import pyro.contrib.examples.util\n",
    "from pyro.infer import SVI, Trace_ELBO\n",
    "from pyro.optim import Adam\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2345148",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We set enable_valudation to False so that the Bernoulli distribution\n",
    "# can accept the images even though the values are in [0, 1] instead of\n",
    "# only values that are 0 or 1.\n",
    "pyro.distributions.enable_validation(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b60f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, z_dim):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(784, 400)\n",
    "        self.fc2 = nn.Linear(400, 100)\n",
    "        self.fc31 = nn.Linear(100, z_dim)\n",
    "        self.fc32 = nn.Linear(100, z_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.reshape(-1, 784)\n",
    "        hidden = torch.tanh(self.fc1(x))\n",
    "        hidden = torch.tanh(self.fc2(hidden))\n",
    "        z_loc = self.fc31(hidden)\n",
    "        z_scale = torch.exp(0.5 * self.fc32(hidden))\n",
    "        return z_loc, z_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0fee30",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BVAE(nn.Module):\n",
    "    def __init__(self, z_dim = 2):\n",
    "        super().__init__()\n",
    "        self.z_dim = z_dim\n",
    "        self.encoder = Encoder(self.z_dim)\n",
    "\n",
    "    def model(self, x):\n",
    "        # Place N(0, 1) priors on the linear layers\n",
    "        w1 = pyro.sample(\"w1\", dist.Normal(0, 1).expand([2, 100]).to_event(2))\n",
    "        b1 = pyro.sample(\"b1\", dist.Normal(0, 1).expand([100]).to_event(1))\n",
    "        w2 = pyro.sample(\"w2\", dist.Normal(0, 1).expand([100, 400]).to_event(2))\n",
    "        b2 = pyro.sample(\"b2\", dist.Normal(0, 1).expand([400]).to_event(1))\n",
    "        w3 = pyro.sample(\"w3\", dist.Normal(0, 1).expand([400, 784]).to_event(2))\n",
    "        b3 = pyro.sample(\"b3\", dist.Normal(0, 1).expand([784]).to_event(1))\n",
    "        with pyro.plate(\"data\", x.shape[0]):\n",
    "            # N(0, 1) prior on the latent variable z\n",
    "            z_loc = x.new_zeros(torch.Size((x.shape[0], self.z_dim)))\n",
    "            z_scale = x.new_ones(torch.Size((x.shape[0], self.z_dim)))\n",
    "            z = pyro.sample(\"z\", dist.Normal(z_loc, z_scale).to_event(1))\n",
    "            hidden = torch.tanh((z @ w1) + b1)\n",
    "            hidden = torch.tanh((hidden @ w2) + b2)\n",
    "            loc_img = torch.sigmoid((hidden @ w3) + b3)\n",
    "            pyro.sample(\"obs\", dist.Bernoulli(loc_img).to_event(1), obs=x.reshape(-1, 784))\n",
    "\n",
    "    def guide(self, x):\n",
    "        # w and b\n",
    "        # We initialize the mean parameters to 0 and the sd parameters to 1.\n",
    "        w1_mu = pyro.param(\"w1_mu\", torch.zeros([2, 100]))\n",
    "        w1_sd = pyro.param(\"w1_sd\", torch.ones([2, 100]),\n",
    "                         constraint = torch.distributions.constraints.positive)\n",
    "        pyro.sample(\"w1\", dist.Normal(w1_mu, w1_sd).to_event(2))\n",
    "        b1_mu = pyro.param(\"b1_mu\", torch.zeros([100]))\n",
    "        b1_sd = pyro.param(\"b1_sd\", torch.ones([100]),\n",
    "                         constraint = torch.distributions.constraints.positive)\n",
    "        pyro.sample(\"b1\", dist.Normal(b1_mu, b1_sd).to_event(1))\n",
    "        w2_mu = pyro.param(\"w2_mu\", torch.zeros([100, 400]))\n",
    "        w2_sd = pyro.param(\"w2_sd\", torch.ones([100, 400]),\n",
    "                         constraint = torch.distributions.constraints.positive)\n",
    "        pyro.sample(\"w2\", dist.Normal(w2_mu, w2_sd).to_event(2))\n",
    "        b2_mu = pyro.param(\"b2_mu\", torch.zeros([400]))\n",
    "        b2_sd = pyro.param(\"b2_sd\", torch.ones([400]),\n",
    "                         constraint = torch.distributions.constraints.positive)\n",
    "        pyro.sample(\"b2\", dist.Normal(b2_mu, b2_sd).to_event(1))\n",
    "        w3_mu = pyro.param(\"w3_mu\", torch.zeros([400, 784]))\n",
    "        w3_sd = pyro.param(\"w3_sd\", torch.ones([400, 784]),\n",
    "                         constraint = torch.distributions.constraints.positive)\n",
    "        pyro.sample(\"w3\", dist.Normal(w3_mu, w3_sd).to_event(2))\n",
    "        b3_mu = pyro.param(\"b3_mu\", torch.zeros([784]))\n",
    "        b3_sd = pyro.param(\"b3_sd\", torch.ones([784]),\n",
    "                         constraint = torch.distributions.constraints.positive)\n",
    "        pyro.sample(\"b3\", dist.Normal(b3_mu, b3_sd).to_event(1))\n",
    "        \n",
    "        # z\n",
    "        pyro.module(\"encoder\", self.encoder)\n",
    "        with pyro.plate(\"data\", x.shape[0]):\n",
    "            z_loc, z_scale = self.encoder(x)\n",
    "            pyro.sample(\"z\", dist.Normal(z_loc, z_scale).to_event(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea5f59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(svi, train_loader):\n",
    "    epoch_loss = 0.\n",
    "    for x, _ in train_loader:\n",
    "        epoch_loss += svi.step(x)\n",
    "\n",
    "    normalizer_train = len(train_loader.dataset)\n",
    "    total_epoch_loss_train = epoch_loss / normalizer_train\n",
    "    return total_epoch_loss_train\n",
    "\n",
    "def evaluate(svi, test_loader):\n",
    "    test_loss = 0.\n",
    "    for x, _ in test_loader:\n",
    "        test_loss += svi.evaluate_loss(x)\n",
    "    normalizer_test = len(test_loader.dataset)\n",
    "    total_epoch_loss_test = test_loss / normalizer_test\n",
    "    return total_epoch_loss_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cbdfc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_data_loaders(batch_size=128):\n",
    "    root = './data'\n",
    "    download = True\n",
    "    trans = transforms.ToTensor()\n",
    "    train_set = MNIST(root=root, train=True, transform=trans,\n",
    "                      download=download)\n",
    "    test_set = MNIST(root=root, train=False, transform=trans)\n",
    "\n",
    "    kwargs = {'num_workers': 1, 'pin_memory': False}\n",
    "    train_loader = torch.utils.data.DataLoader(dataset=train_set,\n",
    "        batch_size=batch_size, shuffle=True, **kwargs)\n",
    "    test_loader = torch.utils.data.DataLoader(dataset=test_set,\n",
    "        batch_size=batch_size, shuffle=False, **kwargs)\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912608fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 1.0e-3\n",
    "\n",
    "NUM_EPOCHS = 1500\n",
    "TEST_FREQUENCY = 5\n",
    "\n",
    "train_loader, test_loader = setup_data_loaders(batch_size=128)\n",
    "\n",
    "pyro.clear_param_store()\n",
    "\n",
    "bvae = BVAE(z_dim = 2)\n",
    "\n",
    "adam_args = {\"lr\": LEARNING_RATE}\n",
    "optimizer = Adam(adam_args)\n",
    "\n",
    "svi = SVI(bvae.model, bvae.guide, optimizer, loss=Trace_ELBO())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf03342",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_elbo = []\n",
    "test_elbo = []\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    total_epoch_loss_train = train(svi, train_loader)\n",
    "    train_elbo.append(-total_epoch_loss_train)\n",
    "    print(\"[epoch %03d]  average training loss: %.4f\" % (epoch, total_epoch_loss_train))\n",
    "\n",
    "    if epoch % TEST_FREQUENCY == 0:\n",
    "        total_epoch_loss_test = evaluate(svi, test_loader)\n",
    "        test_elbo.append(-total_epoch_loss_test)\n",
    "        print(\"[epoch %03d] average test loss: %.4f\" % (epoch, total_epoch_loss_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655cb5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_im = 16\n",
    "batch0 = next(iter(test_loader))[0]\n",
    "plt.imshow(batch0[n_im, :].reshape([28, 28]), cmap = \"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47dd3c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictive = pyro.infer.Predictive(bvae.model, guide = bvae.guide, num_samples = 1)\n",
    "pred = predictive(batch0[n_im])\n",
    "\n",
    "# Use parameters sampled from the variational distributions to reconstruct image\n",
    "\n",
    "hidden = torch.tanh((pred[\"z\"] @ pred[\"w1\"]) + pred[\"b1\"])\n",
    "hidden = torch.tanh((hidden @ pred[\"w2\"]) + pred[\"b2\"])\n",
    "reconstructed = torch.sigmoid((hidden @ pred[\"w3\"]) + pred[\"b3\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57b2989",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.imshow(reconstructed.detach().numpy().reshape([28, 28]), cmap = \"gray\")\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Bayesian VAE: MNIST 9\")\n",
    "plt.show()\n",
    "\n",
    "fig.savefig('bvae.png', format = 'png', dpi = 600, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56f7e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(bvae, \"bvae.pt\")\n",
    "pyro.get_param_store().save(\"bvae_params.pyro\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
