{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "611b31ab",
   "metadata": {},
   "source": [
    "# B2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eafdf86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyro\n",
    "import pyro.contrib.gp as gp\n",
    "import pyro.distributions as dist\n",
    "import torch\n",
    "import arviz\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179cdf2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_to_minimize(x):\n",
    "    return torch.sin(20 * x) + 2 * torch.cos(14 * x) - 2 * torch.sin(6 * x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc669ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (x_data, y_data) correspond to D and will be updated gradually\n",
    "# we initialize them to the points from B1.\n",
    "pyro.clear_param_store()\n",
    "pyro.set_rng_seed(1351)\n",
    "x_data = torch.tensor([-1, -0.5, 0, 0.5, 1])\n",
    "y_data = torch.sin(20 * x_data) + 2 * torch.cos(14 * x_data) - 2 * torch.sin(6 * x_data)\n",
    "rbm_kernel = gp.kernels.RBF(input_dim = 1)\n",
    "rbm_kernel.variance = pyro.nn.PyroSample(dist.LogNormal(0, 2))\n",
    "rbm_kernel.lengthscale = pyro.nn.PyroSample(dist.LogNormal(-1, 1))\n",
    "n_x_new = 200\n",
    "x_new = torch.linspace(-1, 1, steps = n_x_new)\n",
    "n_chains = 1\n",
    "n_warmup = 2000\n",
    "\n",
    "def get_param_sample(x_data, y_data):\n",
    "    pyro.clear_param_store()\n",
    "    gpr = gp.models.GPRegression(x_data, y_data, rbm_kernel, noise=torch.tensor(1e-4))\n",
    "    nuts_kernel = pyro.infer.mcmc.NUTS(gpr.model)\n",
    "    mcmc = pyro.infer.mcmc.MCMC(nuts_kernel, warmup_steps = n_warmup, num_samples = 1, num_chains = 1)\n",
    "    mcmc.run()\n",
    "    samples = mcmc.get_samples()\n",
    "    return samples[\"kernel.lengthscale\"], samples[\"kernel.variance\"]\n",
    "\n",
    "def get_param_samples(x_data, y_data, n_samples_per_chain, n_warmup = n_warmup):\n",
    "    pyro.clear_param_store()\n",
    "    gpr = gp.models.GPRegression(x_data, y_data, rbm_kernel, noise=torch.tensor(1e-4))\n",
    "    nuts_kernel = pyro.infer.mcmc.NUTS(gpr.model)\n",
    "    mcmc = pyro.infer.mcmc.MCMC(nuts_kernel, warmup_steps = n_warmup, num_samples = n_samples_per_chain, num_chains = n_chains)\n",
    "    mcmc.run()\n",
    "    samples = mcmc.get_samples()\n",
    "    return samples[\"kernel.lengthscale\"], samples[\"kernel.variance\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ead652",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iter = 15\n",
    "l = 1.5 # lambda for \n",
    "## We also count how many points we add, since we skip an iteration if we get a non positive-definite covariance matrix\n",
    "count_added = 0\n",
    "m_tensor = torch.empty(n_iter, n_x_new)\n",
    "v_tensor = torch.empty(n_iter, n_x_new)\n",
    "acq_fun_tensor = torch.empty(n_iter, n_x_new)\n",
    "n_samples_per_chain = 20000\n",
    "n_param_samples = n_samples_per_chain * n_chains\n",
    "f_samples = torch.empty(n_param_samples, n_x_new)\n",
    "count_added = 0\n",
    "f_tensor = torch.empty(n_iter, n_x_new)\n",
    "m_tensor = torch.empty(n_iter, n_x_new)\n",
    "v_tensor = torch.empty(n_iter, n_x_new)\n",
    "\n",
    "for i in range(n_iter):\n",
    "    # Sample a lot for m and v\n",
    "    pyro.clear_param_store()\n",
    "    lengthscale_samples, variance_samples = get_param_samples(x_data, y_data, n_samples_per_chain)\n",
    "    m_sample = torch.zeros(n_x_new)\n",
    "    v_sample = torch.zeros(n_x_new)\n",
    "    for j in range(n_param_samples):\n",
    "        pyro.clear_param_store()\n",
    "        rbm_kernel_sample = gp.kernels.RBF(input_dim = 1,\n",
    "                                       variance = variance_samples[j],\n",
    "                                       lengthscale = lengthscale_samples[j])\n",
    "        gpr_sample = gp.models.GPRegression(x_data, y_data, rbm_kernel_sample,\n",
    "                                            noise=torch.tensor(1e-4))\n",
    "        m_sample, v_sample = gpr_sample(x_new, full_cov = False, noiseless = True)\n",
    "        f_dist = dist.MultivariateNormal(m_sample, covariance_matrix=torch.diag(v_sample))\n",
    "        f_sample = f_dist.sample()\n",
    "        f_samples[j, :] = f_sample\n",
    "    m_post = f_samples.mean(dim = 0)\n",
    "    v_post = f_samples.var(dim = 0)\n",
    "    \n",
    "    # Sample a single f*\n",
    "    pyro.clear_param_store()\n",
    "    lengthscale_sample, variance_sample = lengthscale_samples[0], variance_samples[0]\n",
    "    rbm_kernel_sample = gp.kernels.RBF(input_dim = 1,\n",
    "                                       variance = variance_sample,\n",
    "                                       lengthscale = lengthscale_sample)\n",
    "    gpr_sample = gp.models.GPRegression(x_data, y_data, rbm_kernel_sample,\n",
    "                                        noise=torch.tensor(1e-4))\n",
    "    m_sample, cov_sample = gpr_sample(x_new, full_cov = True, noiseless = False)\n",
    "\n",
    "    try:\n",
    "        f_dist = dist.MultivariateNormal(m_sample, covariance_matrix=cov_sample)\n",
    "        f_sample = f_dist.sample()\n",
    "        x_data = torch.cat((x_data, torch.tensor([x_new[torch.argmin(f_sample)]])))\n",
    "        y_data = torch.cat((y_data, torch.tensor([func_to_minimize(x_data[-1])])))\n",
    "        m_tensor[count_added, :] = m_post\n",
    "        v_tensor[count_added, :] = v_post\n",
    "        f_tensor[count_added, :] = f_sample\n",
    "        count_added += 1\n",
    "    except ValueError:\n",
    "        print(\"Not invertible cov\")\n",
    "    print(x_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e76e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_step(i, filename = None):\n",
    "    n_start_points = 5 # Nr of data points used to begin with\n",
    "    # Extract values from tensors\n",
    "    m = m_tensor[i, :].detach().numpy()\n",
    "    v = v_tensor[i, :].detach().numpy()\n",
    "    f_star = f_tensor[i, :].detach().numpy()\n",
    "    xs = x_data[0:(n_start_points + i)].detach().numpy()\n",
    "    ys = y_data[0:(n_start_points + i)].detach().numpy()\n",
    "    x_added = x_data[n_start_points + i]\n",
    "    y_added = y_data[n_start_points + i]\n",
    "    x_new_np = x_new.detach().numpy()\n",
    "    f_values = np.sin(20 * x_new_np) + 2 * np.cos(14 * x_new_np) - 2 * np.sin(6 * x_new_np)\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.plot(x_new_np, m, c='b')\n",
    "    plt.fill_between(x_new_np,\n",
    "                     m - 2 * np.sqrt(v),\n",
    "                     m + 2 * np.sqrt(v),\n",
    "                     alpha=0.2)\n",
    "    ax.plot(x_new_np, f_values, c='g')\n",
    "    ax.plot(x_new_np, f_star, c='purple')\n",
    "    ax.scatter(xs, ys, c='r', marker='o')\n",
    "    ax.scatter(x_added, y_added, c='black', marker='o')\n",
    "    ax.set_xlabel('x')\n",
    "    ax.set_ylabel('y')\n",
    "    plt.legend(['m(x)', '+/- 2*sqrt(v(x))', 'true f', 'sampled f*', 'known f(x)', 'new point'],\n",
    "              loc = \"upper left\", ncol = 3)\n",
    "    plt.title(\"Iteration \" + str(i))\n",
    "    plt.show()\n",
    "    if filename:\n",
    "        fig.savefig('figures/' + filename, format='png', dpi=1200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1696e828",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_step(0, 'b2_iter0.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a58b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_step(5, 'b2_iter5.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e9d54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_step(10, 'b2_iter10.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a8b070",
   "metadata": {},
   "source": [
    "Spørgsmål: Skal m og v bare tages fra den ene sample af theta (ligesom f*) eller skal man tage flere samples af theta for at få et ordentligt estimat af m og v?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fb2e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(f_tensor, \"results/f_tensor.pt\")\n",
    "torch.save(m_tensor, \"results/m_tensor.pt\")\n",
    "torch.save(v_tensor, \"results/v_tensor.pt\")\n",
    "torch.save(x_data, \"results/x_data.pt\")\n",
    "torch.save(y_data, \"results/y_data.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feeeb2c8",
   "metadata": {},
   "source": [
    "Observations om kørsler:\n",
    "\n",
    "- Den finder ikke altid det globale minimum, da den kan blive fanget i det lokale minimum omkring x = -0.7. Selv når den er fanget omkring -0.7 kan man dog være heldig at den hopper over i nærheden af det rigtige minimum.\n",
    "- Den bruger nogen gange flere iterationer på at tilføje -1 som ekstra punkt i starten, fordi det er relativt sandsynligt at sample en f* som har minimum i -1 (fordi det er det mindste af datapunkterne vi har). Dette er bare spild af iterationer, da det slet ikke tilføjer ny information.\n",
    "- En gang imellem får den en ikke invertibel kovarians (selvom vi sampler med støj og tilføjer jitter). Vi springer bare den iteration over - man kunne også evt. skrue op for støj eller jitter der lægges til diagonalen i kovariansmatricen.\n",
    "\n",
    "\n",
    "I praksis ville man også have brug for en metode til at beslutte hvornår man stopper kørslen og tager det sidste punkt som sit estimat."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08dc0af6",
   "metadata": {},
   "source": [
    "## Alternativ metode: UCB (upper confidence bound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f076f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (x_data, y_data) correspond to D and will be updated gradually\n",
    "# we initialize them to the points from B1.\n",
    "pyro.clear_param_store()\n",
    "pyro.set_rng_seed(1357)\n",
    "x_data = torch.tensor([-1, -0.5, 0, 0.5, 1])\n",
    "y_data = torch.sin(20 * x_data) + 2 * torch.cos(14 * x_data) - 2 * torch.sin(6 * x_data)\n",
    "rbm_kernel = gp.kernels.RBF(input_dim = 1)\n",
    "rbm_kernel.variance = pyro.nn.PyroSample(dist.LogNormal(0, 2))\n",
    "rbm_kernel.lengthscale = pyro.nn.PyroSample(dist.LogNormal(-1, 1))\n",
    "n_x_new = 200\n",
    "x_new = torch.linspace(-1, 1, steps = n_x_new)\n",
    "n_chains = 1\n",
    "\n",
    "def get_param_samples(x_data, y_data, n_samples_per_chain, n_warmup = 2000):\n",
    "    pyro.clear_param_store()\n",
    "    gpr = gp.models.GPRegression(x_data, y_data, rbm_kernel, noise=torch.tensor(1e-4))\n",
    "    nuts_kernel = pyro.infer.mcmc.NUTS(gpr.model)\n",
    "    mcmc = pyro.infer.mcmc.MCMC(nuts_kernel, warmup_steps = n_warmup, num_samples = n_samples_per_chain, num_chains = n_chains)\n",
    "    mcmc.run()\n",
    "    samples = mcmc.get_samples()\n",
    "    return samples[\"kernel.lengthscale\"], samples[\"kernel.variance\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae8a193",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iter = 15\n",
    "l = 1.5 # lambda for \n",
    "## We also count how many points we add, since we skip an iteration if we get a non positive-definite covariance matrix\n",
    "count_added = 0\n",
    "m_tensor = torch.empty(n_iter, n_x_new)\n",
    "v_tensor = torch.empty(n_iter, n_x_new)\n",
    "acq_fun_tensor = torch.empty(n_iter, n_x_new)\n",
    "n_samples_per_chain = 20000\n",
    "n_param_samples = n_samples_per_chain * n_chains\n",
    "f_samples = torch.empty(n_param_samples, n_x_new)\n",
    "for i in range(n_iter):\n",
    "    pyro.clear_param_store()\n",
    "    lengthscale_samples, variance_samples = get_param_samples(x_data, y_data, n_samples_per_chain)\n",
    "    m_sample = torch.zeros(n_x_new)\n",
    "    v_sample = torch.zeros(n_x_new)\n",
    "    for j in range(n_param_samples):\n",
    "        pyro.clear_param_store()\n",
    "        rbm_kernel_sample = gp.kernels.RBF(input_dim = 1,\n",
    "                                       variance = variance_samples[j],\n",
    "                                       lengthscale = lengthscale_samples[j])\n",
    "        gpr_sample = gp.models.GPRegression(x_data, y_data, rbm_kernel_sample,\n",
    "                                            noise=torch.tensor(1e-4))\n",
    "        m_sample, v_sample = gpr_sample(x_new, full_cov = False, noiseless = True)\n",
    "        f_dist = dist.MultivariateNormal(m_sample, covariance_matrix=torch.diag(v_sample))\n",
    "        f_sample = f_dist.sample()\n",
    "        f_samples[j, :] = f_sample\n",
    "    ## Catch error with non positive-definite covariance matrix to avoid stopping the loop\n",
    "    m_post = f_samples.mean(dim = 0)\n",
    "    v_post = f_samples.var(dim = 0)\n",
    "    try:\n",
    "        acq_fun = m_post - l * torch.sqrt(v_post)\n",
    "        x_data = torch.cat((x_data, torch.tensor([x_new[torch.argmin(acq_fun)]])))\n",
    "        y_data = torch.cat((y_data, torch.tensor([func_to_minimize(x_data[-1])])))\n",
    "        m_tensor[count_added, :] = m_post\n",
    "        v_tensor[count_added, :] = v_post\n",
    "        acq_fun_tensor[count_added, :] = acq_fun\n",
    "        count_added += 1\n",
    "    except ValueError:\n",
    "        print(\"Not invertible cov\")\n",
    "    print(x_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5484d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_step(i, filename = None):\n",
    "    n_start_points = 5 # Nr of data points used to begin with\n",
    "    # Extract values from tensors\n",
    "    m = m_tensor[i, :].detach().numpy()\n",
    "    v = v_tensor[i, :].detach().numpy()\n",
    "    acq_fun = acq_fun_tensor[i, :].detach().numpy()\n",
    "    xs = x_data[0:(n_start_points + i)].detach().numpy()\n",
    "    ys = y_data[0:(n_start_points + i)].detach().numpy()\n",
    "    x_added = x_data[n_start_points + i]\n",
    "    y_added = y_data[n_start_points + i]\n",
    "    x_new_np = x_new.detach().numpy()\n",
    "    f_values = np.sin(20 * x_new_np) + 2 * np.cos(14 * x_new_np) - 2 * np.sin(6 * x_new_np)\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.plot(x_new_np, m, c='b')\n",
    "    plt.fill_between(x_new_np,\n",
    "                     m - 2 * np.sqrt(v),\n",
    "                     m + 2 * np.sqrt(v),\n",
    "                     alpha=0.2)\n",
    "    ax.plot(x_new_np, f_values, c='g')\n",
    "    ax.plot(x_new_np, acq_fun, c='purple')\n",
    "    ax.scatter(xs, ys, c='r', marker='o')\n",
    "    ax.scatter(x_added, y_added, c='black', marker='o')\n",
    "    ax.set_xlabel('x')\n",
    "    ax.set_ylabel('y')\n",
    "    plt.legend(['m(x)', '+/- 2*sqrt(v(x))', 'true f', 'acq. function', 'known f(x)', 'new point'],\n",
    "               loc='upper left', ncol = 3)\n",
    "    plt.title(\"Iteration \" + str(i))\n",
    "    plt.show()\n",
    "    if filename:\n",
    "        fig.savefig('figures/' + filename, format='png', dpi=1200)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972773f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_step(0, 'b2_ucb_iter0.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7452170d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_step(5, 'b2_ucb_iter5.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1616d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_step(10, 'b2_ucb_iter10.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6649ce12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(f_tensor, \"results_step/acq_fun_tensor.pt\")\n",
    "torch.save(m_tensor, \"results_step/m_tensor.pt\")\n",
    "torch.save(v_tensor, \"results_step/v_tensor.pt\")\n",
    "torch.save(x_data, \"results_step/x_data.pt\")\n",
    "torch.save(y_data, \"results_step/y_data.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
